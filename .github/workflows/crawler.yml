name: Hot News Crawler

on:
  schedule:
    # æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ github å®˜æ–¹æä¾›çš„èµ„æºæ¥è¿›è¡Œçš„æ¨é€ï¼Œè€Œæ¯ä¸ªè´¦å·çš„èµ„æºæ˜¯é™é¢çš„ï¼Œä¸ºäº†ä¸è¢«å®˜æ–¹åˆ¤å®šä¸ºæ»¥ç”¨è€Œé¢ä¸´å°å·çš„é£é™©ï¼Œä¸å»ºè®®æ¯”åŠå°æ—¶æ›´ä½
    - cron: "0 * * * *" # æ¯å°æ—¶æ•´ç‚¹è¿è¡Œä¸€æ¬¡(å®é™…æœ‰åå·®) æˆ–è€… "*/30 * * * *" (æ¯åŠå°æ—¶æ‰§è¡Œä¸€æ¬¡) æˆ–è€… "*/30 0-14 * * *"(æ¯å¤©æ—©ä¸Š 8 ç‚¹åˆ°æ™šä¸Š 10 ç‚¹æœŸé—´ï¼Œæ¯åŠå°æ—¶è¿è¡Œä¸€æ¬¡)
  workflow_dispatch:

# æ·»åŠ æƒé™è®¾ç½®
permissions:
  contents: write

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 30  # å¢åŠ è¶…æ—¶æ—¶é—´ä»¥æ”¯æŒPlaywrightå®‰è£…

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Set up Node.js for Playwright
        uses: actions/setup-node@v3
        with:
          node-version: "18"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          echo "ğŸ­ å®‰è£…Playwrightæµè§ˆå™¨..."
          playwright install chromium
          playwright install-deps chromium

      - name: Verify Playwright installation
        run: |
          echo "ğŸ” éªŒè¯Playwrightå®‰è£…..."
          python -c "
          try:
              from playwright.sync_api import sync_playwright
              print('âœ… PlaywrightåŒæ­¥APIå¯¼å…¥æˆåŠŸ')
          except ImportError as e:
              print(f'âŒ PlaywrightåŒæ­¥APIå¯¼å…¥å¤±è´¥: {e}')
              exit(1)
          
          try:
              from playwright.async_api import async_playwright
              print('âœ… Playwrightå¼‚æ­¥APIå¯¼å…¥æˆåŠŸ')
          except ImportError as e:
              print(f'âŒ Playwrightå¼‚æ­¥APIå¯¼å…¥å¤±è´¥: {e}')
              exit(1)
          
          print('âœ… Playwrightå®‰è£…éªŒè¯é€šè¿‡')
          "

      - name: Verify required files
        run: |
          echo "ğŸ” æ£€æŸ¥å¿…éœ€çš„é…ç½®æ–‡ä»¶..."

          if [ ! -f config/config.yaml ]; then
            echo "âŒ é”™è¯¯: config/config.yaml æ–‡ä»¶ä¸å­˜åœ¨"
            echo "è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£åˆ›å»ºé…ç½®æ–‡ä»¶"
            exit 1
          fi

          if [ ! -f config/frequency_words.txt ]; then
            echo "âŒ é”™è¯¯: config/frequency_words.txt æ–‡ä»¶ä¸å­˜åœ¨"
            echo "è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£åˆ›å»ºé¢‘ç‡è¯é…ç½®æ–‡ä»¶"
            exit 1
          fi

          echo "âœ… é…ç½®æ–‡ä»¶æ£€æŸ¥é€šè¿‡"

      - name: Test gold scraper functionality
        env:
          GITHUB_ACTIONS: true
        run: |
          echo "ğŸ§ª æµ‹è¯•é»„é‡‘çˆ¬è™«åŠŸèƒ½..."
          python -c "
          import sys
          import os
          sys.path.append('src')
          
          try:
              from gold_scraper import initialize_gold_scraper, get_system_status
              print('âœ… é»„é‡‘çˆ¬è™«æ¨¡å—å¯¼å…¥æˆåŠŸ')
              
              # åˆå§‹åŒ–ç³»ç»Ÿ
              if initialize_gold_scraper():
                  print('âœ… é»„é‡‘çˆ¬è™«ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ')
                  
                  # è·å–ç³»ç»ŸçŠ¶æ€
                  status = get_system_status()
                  print(f'ğŸ“Š ç³»ç»ŸçŠ¶æ€: {status}')
              else:
                  print('âš ï¸ é»„é‡‘çˆ¬è™«ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½†ä¸å½±å“ä¸»ç¨‹åºè¿è¡Œ')
                  
          except ImportError as e:
              print(f'âš ï¸ é»„é‡‘çˆ¬è™«æ¨¡å—å¯¼å…¥å¤±è´¥: {e}')
              print('âš ï¸ å°†ä½¿ç”¨APIæ¨¡å¼è¿è¡Œï¼Œä¸å½±å“ä¸»ç¨‹åºåŠŸèƒ½')
          except Exception as e:
              print(f'âš ï¸ é»„é‡‘çˆ¬è™«æµ‹è¯•å¤±è´¥: {e}')
              print('âš ï¸ å°†ä½¿ç”¨APIæ¨¡å¼è¿è¡Œï¼Œä¸å½±å“ä¸»ç¨‹åºåŠŸèƒ½')
          
          print('âœ… é»„é‡‘çˆ¬è™«åŠŸèƒ½æµ‹è¯•å®Œæˆ')
          "

      - name: Run crawler
        env:
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
          WEWORK_WEBHOOK_URL: ${{ secrets.WEWORK_WEBHOOK_URL }}
          GITHUB_ACTIONS: true
          # é»„é‡‘çˆ¬è™«ç›¸å…³ç¯å¢ƒå˜é‡
          GOLD_SCRAPER_ENABLED: true
          GOLD_SCRAPER_FALLBACK_MODE: true
        run: python main.py

      - name: Commit and push if changes
        run: |
          git config --global user.name 'GitHub Actions'
          git config --global user.email 'actions@github.com'
          git add -A
          git diff --quiet && git diff --staged --quiet || (git commit -m "Auto update by GitHub Actions at $(TZ=Asia/Shanghai date)" && git push)